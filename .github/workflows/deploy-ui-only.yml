name: Deploy UI Updates

on:
  push:
    branches: [main]
    paths: ['network-viz/**']
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  deploy-ui:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download previous complete site artifact
        run: |
          # Try to get the most recent complete-site artifact from ANY workflow
          echo "Looking for previous complete site artifact to preserve data..."

          # Get all recent runs from all workflows in the repository
          gh run list --repo ${{ github.repository }} --limit 50 --json databaseId,status,conclusion,createdAt,workflowName \
            --jq '.[] | select(.status == "completed" and .conclusion == "success") | [.databaseId, .workflowName, .createdAt] | @tsv' \
            | sort -k3 -r > recent_runs.tsv

          FOUND_ARTIFACT=false

          while IFS=$'\t' read -r run_id workflow_name created_at && [ "$FOUND_ARTIFACT" = false ]; do
            echo "Checking run $run_id ($workflow_name, $created_at) for complete-site artifact..."

            # Check if this run has a complete-site artifact
            if gh run view "$run_id" --repo ${{ github.repository }} --json artifacts --jq '.artifacts[].name' | grep -q '^complete-site$'; then
              echo "Found complete-site artifact in run $run_id from workflow: $workflow_name"

              # Try to download the artifact
              if gh run download "$run_id" --repo ${{ github.repository }} --name "complete-site" --dir ./previous_site/; then
                echo "Successfully downloaded complete-site artifact"
                FOUND_ARTIFACT=true
                break
              else
                echo "Failed to download artifact from run $run_id, trying next..."
              fi
            fi
          done < recent_runs.tsv

          if [ "$FOUND_ARTIFACT" = true ]; then
            echo "Previous site downloaded successfully"
            # Extract the previous site to preserve all data
            if [ -f "previous_site/site.tar.gz" ]; then
              tar -xzf previous_site/site.tar.gz
              echo "Previous site extracted - $(find pages_output -type f | wc -l) files restored"

              # Preserve the data directory
              if [ -d "pages_output/public/data" ]; then
                echo "Preserved existing scan data"
              fi
            else
              echo "Previous site archive not found, starting fresh"
              mkdir -p pages_output/public/data
            fi
          else
            echo "No previous complete-site artifact found, starting fresh"
            mkdir -p pages_output/public/data
          fi
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "18"
          cache: "npm"
          cache-dependency-path: network-viz/package-lock.json

      - name: Build and deploy updated UI
        run: |
          # Build the updated visualization
          cd network-viz
          npm ci
          npm run build

          # Replace only the UI files, preserve data directory
          echo "Updating UI while preserving data..."

          # Remove old UI files but keep data
          find ../pages_output -maxdepth 1 -type f -delete 2>/dev/null || true
          rm -rf ../pages_output/assets 2>/dev/null || true

          # Copy new UI build to pages output, preserving scan data
          echo "Copying UI files while preserving scan data..."

          # Copy all top-level files (index.html, vite.svg, etc.)
          find dist -maxdepth 1 -type f -exec cp {} ../pages_output/ \;

          # Copy assets directory (CSS, JS)
          if [ -d "dist/assets" ]; then
            cp -r dist/assets ../pages_output/
          fi

          # Handle the data directory from Vite build (public/data -> dist/data)
          if [ -d "dist/data" ]; then
            # Create public directory structure for GitHub Pages
            mkdir -p ../pages_output/public

            # Only copy build data if no existing scan data
            if [ ! -d "../pages_output/public/data" ] || [ ! -f "../pages_output/public/data/manifest.json" ]; then
              echo "No existing scan data found, copying empty data structure..."
              cp -r dist/data ../pages_output/public/
            else
              echo "Preserved existing scan data ($(find ../pages_output/public/data -name "*.json" | wc -l) JSON files)"
              echo "Skipping dist/data to avoid overwriting scan results"
            fi
          fi

          echo "UI updated, data preserved"
          echo "Total files in deployment: $(find ../pages_output -type f | wc -l)"
          echo "Data files preserved: $(find ../pages_output/public/data -name "*.json" | wc -l) JSON files"

      - name: Create and upload complete site artifact
        run: |
          # Create a compressed archive of the complete site (UI + preserved data)
          tar -czf site.tar.gz pages_output/
          echo "Complete site archived for future builds"

      - name: Upload complete site artifact
        uses: actions/upload-artifact@v4
        with:
          name: complete-site
          path: site.tar.gz
          retention-days: 30

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: "./pages_output"

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4